# kafka source 
kafka.bootstrap.servers.source=localhost:9092
inputTopicName=input-test
maxOffsetsPerTrigger=10000
startingOffsets=earliest


#user can choose jdbc for hourly report( for update mode) or kafka for complete report log
outputMode=kafka

# mysql jdbc sink ( only needed if output mode is jdbc).
# The corresponding "report" table should be created as described in read-me file.
url=jdbc:mysql://localhost/test
user=root
password=root
tableName=test-table

# kafka sink ( only needed if output mode is kafka)
kafka.bootstrap.servers.sink=localhost:9092
outputTopicName=output-test
checkPointSink=/home/pintoo/Documents/test_checkpoint2

#raw storage
checkpointRaw=/home/pintoo/Documents/test_checkpoint1
outputPath=/home/pintoo/Documents/test_rawdata

# spark master
sparkMaster=local[2]