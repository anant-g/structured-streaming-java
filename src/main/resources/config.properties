# kafka source 
kafka.bootstrap.servers.source=localhost:9092
inputTopicName=market-data-input
maxOffsetsPerTrigger=10000
startingOffsets=earliest


#user can choose jdbc for hourly report( for update mode real time) or kafka for complete report log
outputMode=jdbc

# mysql jdbc sink ( only needed if output mode is jdbc).
# The corresponding "report" table should be created as described in read-me file.
url=jdbc:mysql://localhost/test
user=root
password=root
tableName=report

# kafka sink ( only needed if output mode is kafka)
kafka.bootstrap.servers.sink=localhost:9092
outputTopicName=market-data
checkPointSink=/home/anant/checkpoint2

#raw storage
checkpointRaw=/home/anant/checkpoint1
outputPath=/home/anant/rawdata

# spark master
sparkMaster=local[*]